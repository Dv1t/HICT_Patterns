{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-21T15:46:50.294650700Z",
     "start_time": "2023-07-21T15:46:47.972993500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import pathlib\n",
    "print(tf.config.list_physical_devices('CPU'))\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,AveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import LearningRateScheduler,ReduceLROnPlateau\n",
    "from keras.optimizers import Adam # I believe this is better optimizer for our case"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Загрузка датасета и связанных гиперпараметров"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('datasets/images_center_10')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T15:50:29.755605100Z",
     "start_time": "2023-07-21T15:50:29.735413900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 20\n",
    "img_width = 20\n",
    "num_classes = 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T15:47:05.178246500Z",
     "start_time": "2023-07-21T15:47:05.172471100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5804 files belonging to 2 classes.\n",
      "Using 4644 files for training.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:CPU:0'):\n",
    "  train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T15:50:38.696513300Z",
     "start_time": "2023-07-21T15:50:38.388539200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5804 files belonging to 2 classes.\n",
      "Using 1160 files for validation.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:CPU:0'):\n",
    "  val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T15:50:39.498489600Z",
     "start_time": "2023-07-21T15:50:39.195265600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'positive']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T15:50:42.084799800Z",
     "start_time": "2023-07-21T15:50:42.069129800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "with tf.device('/device:CPU:0'):\n",
    "  AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "  train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "  val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T15:50:43.505464600Z",
     "start_time": "2023-07-21T15:50:43.488645600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Определение моделей и методов для работы с ними"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def create_model_cnn(input_shape=(img_height, img_width), num_classes=num_classes):\n",
    "  model = Sequential([\n",
    "  keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3), name='rescaling_1_1'),\n",
    "  keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  keras.layers.MaxPooling2D(),\n",
    "  keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  keras.layers.MaxPooling2D(),\n",
    "  keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  keras.layers.MaxPooling2D(),\n",
    "  keras.layers.Dropout(0.2),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(128, activation='relu'),\n",
    "  keras.layers.Dense(num_classes)\n",
    "  ])\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T15:47:15.093662900Z",
     "start_time": "2023-07-21T15:47:15.088309500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def create_model_cnn_2(input_shape=(img_height, img_width), num_classes=num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3), name='rescaling_2_1'))\n",
    "    model.add(Conv2D(32, kernel_size = (3,3), activation='relu', input_shape = input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, kernel_size = (3,3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, kernel_size = (5,5), strides=2, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(128, kernel_size = 3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation = \"sigmoid\"))\n",
    "    model.compile(optimizer = 'adam' , loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T15:47:15.800859400Z",
     "start_time": "2023-07-21T15:47:15.786511700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def create_LeNet5(input_shape=(img_height, img_width), num_classes=num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3), name='rescaling_3_1'))\n",
    "    model.add(Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=input_shape, padding=\"same\"))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n",
    "    model.add(Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='valid'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "    model.add(Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='valid'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "    model.compile(optimizer =  'adam' , loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T15:47:16.900267700Z",
     "start_time": "2023-07-21T15:47:16.893442200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    with tf.device('/device:CPU:0'):\n",
    "        history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs)\n",
    "        return history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T15:50:47.542610200Z",
     "start_time": "2023-07-21T15:50:47.527644500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Создание моделей"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "model_cnn = create_model_cnn()\n",
    "model_cnn_2 = create_model_cnn_2()\n",
    "model_LeNet = create_LeNet5()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Обучение"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "history_cnn = train_model(model_cnn, 30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "history_cnn_2 = train_model(model_cnn_2, 30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "history_LeNet = train_model(model_LeNet, 30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "model_cnn.save_weights('model_cnn_weights/checkpoint')\n",
    "model_cnn_2.save_weights('model_cnn_2_weights/checkpoint')\n",
    "model_LeNet.save_weights('model_LeNet_weights/checkpoint')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T20:42:56.050095900Z",
     "start_time": "2023-06-13T20:42:55.765403200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Загрузка сохранённых моделей"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x201fbd85390>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.load_weights('model_cnn_weights/checkpoint')\n",
    "model_cnn_2.load_weights('model_cnn_2_weights/checkpoint')\n",
    "model_LeNet.load_weights('model_LeNet_weights/checkpoint')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T15:50:54.327098400Z",
     "start_time": "2023-07-21T15:50:54.182332600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Создание ансамбля"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from keras import Model, Input\n",
    "from keras.layers import Average\n",
    "from typing import List\n",
    "from tensorflow import Tensor\n",
    "from keras.utils.version_utils import training\n",
    "\n",
    "model_input = Input(shape=(img_height, img_width, 3))\n",
    "def ensemble(models: List [training.Model]) -> training.Model:\n",
    "\n",
    "    outputs = [model.outputs[0] for model in models]\n",
    "    y = Average()(outputs)\n",
    "\n",
    "    model = Model(model_input , y, name='ensemble')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T15:50:57.036525Z",
     "start_time": "2023-07-21T15:50:57.026500500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "models = [model_cnn, model_cnn_2, model_LeNet]\n",
    "ensemble_model = ensemble(models)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "<KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'dense_4')>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.outputs[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Использование модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cooler\n",
    "\n",
    "chr = 'X'\n",
    "resolution = 10000\n",
    "c = cooler.Cooler(f'data/ARAb_vs_Coluzzii/ARAB_vs_Coluzzii_4DN.mcool::/resolutions/{resolution}')\n",
    "matrix = c.matrix(balance=False).fetch(chr)\n",
    "\n",
    "src_matrix = np.log10(matrix+1)\n",
    "max_value = np.nanmax(src_matrix)\n",
    "min_value = np.nanmin(src_matrix)\n",
    "for i in range(10, src_matrix.shape[0]-10):\n",
    "        point = (i, i)\n",
    "        point_area = src_matrix[point[1]-10:point[1]+10, point[0]-10:point[0]+10]\n",
    "        plt.imsave(f'datasets/ac_test_images_center_{resolution//1000}/unknown/{chr}_{i*resolution}_{i*resolution}.png',  point_area, cmap='gray', vmax=max_value, vmin=min_value)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "with open('data/ac_detected_rearrangements_ensemble_10.csv', mode='w') as output:\n",
    "  output.write(\"chr,start,end\\n\")\n",
    "  for path in os.listdir('datasets/ac_test_images_center_10/unknown'):\n",
    "      img_path = os.path.join('datasets/ac_test_images_center_10/unknown', path)\n",
    "      with tf.device('/device:CPU:0'):\n",
    "        img = tf.keras.utils.load_img(\n",
    "            img_path, target_size=(img_height, img_width)\n",
    "        )\n",
    "        img_array = tf.keras.utils.img_to_array(img)\n",
    "        img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "        predictions_cnn = np.array(model_cnn(img_array))\n",
    "        predictions_cnn_2 = np.array(model_cnn_2(img_array))\n",
    "        predictions_LeNet = np.array(model_LeNet(img_array))\n",
    "        predictions = (predictions_cnn + predictions_cnn_2 + predictions_LeNet) / 3\n",
    "\n",
    "        score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "        if np.argmax(score) == 1:\n",
    "          path_splited = path.split('_')\n",
    "          output.write(f\"X,{path_splited[1]},{path_splited[2].split('.')[0]}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
